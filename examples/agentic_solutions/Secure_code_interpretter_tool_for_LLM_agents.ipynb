{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fde7616369c1e1e",
   "metadata": {},
   "source": [
    "## Building an Agentic Application with Dynamically Generated Tool Calling\n",
    " \n",
    "Function or tool calling is a powerful feature of LLMs that allows the LLM to call a function with arguments. This is a powerful way to extend the capabilities of LLMs to perform complex tasks. Typically, the function is defined by the developer and passed to the LLM as part of the prompt. The developer needs to pre-define the function, its arguments, and the expected output. \n",
    "\n",
    "\n",
    "In context of this Cookbook, **Dynamically Generated Tool is a function or code block that is generated by the LLM itself at runtime based on the user's prompt**.  This is a powerful way to extend the capabilities of LLMs to perform complex tasks, where the developer does not need to pre-define the function thus constraining the LLM's ability to set of pre-defined scenarios. \n",
    "\n",
    "In this paradigm, **Dynamically Generated Tool Calling is giving the LLM ability to dynamically generate and execute a code block at runtime.** \n",
    "\n",
    "This Cookbook demonstrates how to implement an “agentic” application — one that can generate and execute a tool call in pursuit of a specified goal at runtime. Large Language Models (LLMs) such as OpenAI o1 can generate sophisticated code, making them highly valuable for tasks such as AI assisted programming. We'll use this capability to generate function code for dynamic tools that can be executed in an isolated sandbox environment. \n",
    "\n",
    "Such an dynamic approach can be applied to a wide array of tasks, including: Data analysis and Visualization, Data manipulation and Transformation, Generating and Execution Machine Learning workloads, Process automation and Scription, ... and many more that will emerge as we experiment with this dynamic tool calling framework. \n",
    "\n",
    "**Following this Cookbook, you will learn:**  \n",
    "1.\tSet up an isolated Python code execution environment using Docker\n",
    "2.\tConfigure your own code interpreter tool for LLM agents\n",
    "3.\tSetup a clear separation of Agentic concerns for security and safety\n",
    "4.\tOrchestrate agents to efficiently accomplish a given task \n",
    "5.\tAgentic application that can dynamically generate and execute code\n",
    "\n",
    "**Prerequisites:** \n",
    "Review the [Object-Oriented Approach to Designing Agentic LLM Solutions](./Object_oriented_approach_to_designing_agentic_LLM_solutions.ipynb) Cookbook to understand the core classes and principles for designing Agentic LLM solutions with a focus on Object-Oriented Programming (OOP). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43502bac4a403b4b",
   "metadata": {},
   "source": [
    "#### ⚠️ A WORD OF CAUTION:        \n",
    "##### LLMs could generate harmful code with unintended consequences. As a best practice, isolate the code execution environment with only required read-only access to resources as needed by the task. This Cookbook will demonstrate an option to accomplish this goal using Docker to create a sandbox environment for code execution. **Do not auto execute LLM generated code on your host machine.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd93887",
   "metadata": {},
   "source": [
    "Let's consider a scenario where given a set of data, we want the LLM to answer a set of question. The data is in the form of a CSV files ![AAPL.csv](./resources/data/AAPL.csv) containing Apple's financial data with thousands of rows, and ![AAPL_2024.csv](./resources/data/AAPL_2024.csv) containing Apple's financial data for the last 15 years. Here are some questions we want the LLM to answer:\n",
    "1. What was Apple's year on year Revenue growth from 2009 to 2024? \n",
    "2. What was Apple's closing price on a given date? \n",
    "3. What was Apple's total return for a given year? \n",
    "4. Plot the closing price of Apple over time. \n",
    "\n",
    "Using the traditional **Static Tool Calling** approach, we would need to pre-define the function for each of these questions. This would limit the LLM's ability answer any other questions not defined in the pre-defined set of functions. We overcome this limitation by using the **Dynamic Tool Calling** approach where the LLM generates and executes a function at runtime based on the user's prompt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301abe8",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Let's dive into the steps to build the Agentic Applicaiton with Dynamic Tool Calling. There are three components to this application:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2269f",
   "metadata": {},
   "source": [
    "#### Step 1: Set up an isolated Python code execution environment\n",
    "\n",
    "We need a secure environment where our LLM generated function calls can be executed. Given the word of caution, we want to avoid directly running the LLM generated code on the host machine. We will use a Docker container environment with restricted resource access (e.g., no network access). By default, Docker containers cannot access the host machine’s file system, which helps ensure that any code generated by the LLM remains contained. \n",
    "\n",
    "Within this container, we will preconfigure the necessary tools and libraries for data analysis and visualization—namely Python and commonly used Python libraries. This container can also be setup for task specific requirements such as access the an internal database for read-only access, or machine learning libraries such as Pyspark, Pytorch, Tensorflow, etc. \n",
    "\n",
    "#### Step 2: Define and Test the Agents\n",
    "\n",
    "Let's fitst answer the question \"**What is an Agent?**\" before we define our agents. In the context of this Cookbook, an Agent is:\n",
    "1. Set of instructions for the LLM to follow, i.e. the developer prompt\n",
    "2. A LLM model, and ability to call the model via the API \n",
    "3. Tool call access to a function, and ability to call the function \n",
    "\n",
    "For our purposes, we will define two agents. \n",
    "1.\t**Agent 1: File Access Agent (with Static Tool Calling)**\n",
    "- Instructions to understand the contents of the file to provide as context to Agent 2.\n",
    "- Has access to the host machine’s file system. \n",
    "- Can read a file from the host and copy it into the Docker container.\n",
    "- Cannot access the code interpreter tool. \n",
    "\n",
    "2.\t**Agent 2: Python Code Generator and Executor (with Dynamically Generated Tool Calling)**\n",
    "- Recieve the file content's context from Agent 1.\n",
    "- Instructions to generate a Python script to answer the user's question.\n",
    "- Has access to the code interpreter within the Docker container, which is used to execute Python code.\n",
    "- Has access only to the file system inside the Docker container (not the host).\n",
    "- Cannot access the host machine’s file system or the network.\n",
    "\n",
    "This separation concerns of the File Access (Agent 1) and the Code Generator and Executor (Agent 2) is crucial to prevent the LLM from directly accessing or modifying the host machine. **Limit the Agent 1 to Static Tool Calling as it has access to the host file system.**\n",
    "\n",
    "| Agent | Type of Tool Call | Access to Host File System | Access to Docker Container File System | Access to Code Interpreter |\n",
    "|-------|-------------------|----------------------------|----------------------------------------|----------------------------|\n",
    "| Agent 1: File Access | Static or Pre-defined | Yes | Yes | No |\n",
    "| Agent 2: Python Code Generator and Executor | Dynamic | No | Yes | Yes |\n",
    "\n",
    "\n",
    "#### Step 3: Set up Agentic Orchestration to run the application \n",
    "There are various ways to orchestrate the Agents based on the application requirements. In this example, we will use a simple orchestration where the user provides a task and the agents are called in sequence to accomplish the task. The overall orchestration is shown below:\n",
    "\n",
    "![Agentic Workflow Orchestration](./resources/images/AgenticWorkflow.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a651f8d",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "Before you begin, ensure you have the following installed and configured on your host machine:\n",
    "\n",
    "1. Docker: installed and running on your local machine. You can learn more about Docker and [install it from here](https://www.docker.com/). \n",
    "2. Python: installed on your local machine. You can learn more about Python and [install it from here](https://www.python.org/downloads/). \n",
    "3. OpenAI API key: set up on your local machine as an environment variable. You can learn more about OpenAI API key and [set it up from here](https://platform.openai.com/docs/api-reference/introduction). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea3005fbd91c61",
   "metadata": {},
   "source": [
    "### Step 1: Set up an Isolated Python Code Execution Environment \n",
    "\n",
    "Lets define a Dockerized container environment that will be used to execute our code. I have defined the dockerfile in the directory `resources/docker/dockerfile` that will be used to create the container environment with the following specifications:\n",
    "- Python 3.10 as the base \n",
    "- A non-root user \n",
    "- Preinstall the packages in requirements.txt  \n",
    "\n",
    "Contents of the dockerfile:\n",
    "\n",
    "```dockerfile\n",
    "# Use Python 3.10 as the base image\n",
    "FROM python:3.10\n",
    "\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y build-essential && \\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Create a non-root user\n",
    "RUN useradd -m sandboxuser\n",
    "USER sandboxuser\n",
    "WORKDIR /home/sandboxuser\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "CMD [\"python\", \"--version\"]\n",
    "```\n",
    "The requirements.txt file contains all the potential packages our LLM generated code may need to accomplish its tasks. Given we will restrict the container from network access, so we need to pre-install the packages that are required for the task. Our LLM will not be allowed to install any additional packages for security purposes. \n",
    "\n",
    "This file is copied into the docker container and the packages are installed:\n",
    "\n",
    "```\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2af004",
   "metadata": {},
   "source": [
    "Let's build the docker image with the following command. For the sake of brevity, I have redirected the output to grep the success message and print a message if the build fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe136739b0bd164a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T22:01:49.499773Z",
     "start_time": "2024-12-21T22:01:48.677424Z"
    }
   },
   "outputs": [],
   "source": [
    "!docker build -t python_sandbox:latest ./resources/docker 2>&1 | grep -E \"View build details|ERROR\" || echo \"Build failed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0e9024894d45d",
   "metadata": {},
   "source": [
    "Let's run the container in restricted mode. The container will run in the background. This is our opportunity to define the security policies for the container. It is good practice to only allow the bare minimum features to the container that are required for the task. By default, the container cannot access the host file system from within the container. Let's also restrict its access to network so it cannot access the Internet or any other network resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa0418f90fde09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T22:14:17.304389Z",
     "start_time": "2024-12-21T22:14:16.724650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run the container in restricted mode. The container will run in the background.\n",
    "!docker run -d --name sandbox --network none --cap-drop all --pids-limit 64 --tmpfs /tmp:rw,size=64M   python_sandbox:latest sleep infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21cafbcfdc09e2c",
   "metadata": {},
   "source": [
    "Let's make sure container is running using the `docker ps` that should list our container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df845011b77a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T22:14:22.642396Z",
     "start_time": "2024-12-21T22:14:22.486988Z"
    }
   },
   "outputs": [],
   "source": [
    "!docker ps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42a2c8f40710c2",
   "metadata": {},
   "source": [
    "### Step 2: Define and Test the Agents\n",
    "\n",
    "As defined in the overview, we will create two agents. \n",
    "1. File Access Agent (with Static Tool Calling)\n",
    "2. Python Code Generator and Executor (with Dynamic Tool Calling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d4d2ba5d47226",
   "metadata": {},
   "source": [
    "Let's define a set of core classes that will be used to create the two agents.\n",
    "\n",
    "BaseAgent: We start with an abstract base class that enforces a task method signature. This ensures that all concrete agents will implement task consistently.\n",
    "ChatMessages: A class to store the conversation history.\n",
    "ToolManager: A class to manage the tools that an agent can call.\n",
    "ToolInterface: An abstract class for any 'tool' that an agent can call.\n",
    "\n",
    "These classes are defined in the `resources/core_classes` directory. Let's add the parent directory to the Python path so we can import these classes in our notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add the parent directory of 'core_classes' to the Python path\n",
    "sys.path.append(os.path.abspath('resources/object_oriented_agents/core_classes'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb923b",
   "metadata": {},
   "source": [
    "**Defining FileAccessAgent**\n",
    "\n",
    "Let's start with definin the FileAccessTool that the FileAccessAgent will use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09facd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "from examples.agentic_solutions.resources.object_oriented_agents.core_classes.tool_interface import ToolInterface\n",
    "\n",
    "class FileAccessTool(ToolInterface):\n",
    "    \"\"\"\n",
    "    A tool to read CSV files and copy them to a Docker container.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_definition(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"function\": {\n",
    "                \"name\": \"safe_file_access\",\n",
    "                \"description\": (\n",
    "                    \"Read the contents of a file in a secure manner \"\n",
    "                    \"and transfer it to the Python code interpreter docker container\"\n",
    "                ),\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"filename\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Name of the file to read\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"filename\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def run(self, arguments: Dict[str, Any]) -> str:\n",
    "        filename = arguments[\"filename\"]\n",
    "        return self.safe_file_access(filename)\n",
    "\n",
    "    def safe_file_access(self, filename: str) -> str:\n",
    "        if not filename.endswith('.csv'):\n",
    "            return \"Error: The file is not a CSV file.\"\n",
    "\n",
    "        # Ensure the path is correct\n",
    "        if not os.path.dirname(filename):\n",
    "            filename = os.path.join('./resources/data', filename)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            copy_output = self.copy_file_to_container(filename)\n",
    "            head_str = df.head(6).to_string()\n",
    "            return f\"{copy_output}\\nThe file content for the first 6 rows is:\\n{head_str}\"\n",
    "        except FileNotFoundError:\n",
    "            return f\"Error: The file '{filename}' was not found.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error while reading the CSV file: {str(e)}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def copy_file_to_container(local_file_name: str, container_name: str = \"sandbox\") -> str:\n",
    "        container_home_path = \"/home/sandboxuser\"\n",
    "\n",
    "        if not os.path.isfile(local_file_name):\n",
    "            raise FileNotFoundError(f\"The local file '{local_file_name}' does not exist.\")\n",
    "\n",
    "        # Check if container is running\n",
    "        check_container_cmd = [\"docker\", \"inspect\", \"-f\", \"{{.State.Running}}\", container_name]\n",
    "        result = subprocess.run(check_container_cmd, capture_output=True, text=True)\n",
    "        if result.returncode != 0 or result.stdout.strip() != \"true\":\n",
    "            raise RuntimeError(f\"The container '{container_name}' is not running.\")\n",
    "\n",
    "        # Copy the file into the container\n",
    "        container_path = f\"{container_name}:{container_home_path}/{os.path.basename(local_file_name)}\"\n",
    "        subprocess.run([\"docker\", \"cp\", local_file_name, container_path], check=True)\n",
    "\n",
    "        # Verify the file was copied\n",
    "        verify_cmd = [\"docker\", \"exec\", container_name, \"test\", \"-f\",\n",
    "                      f\"{container_home_path}/{os.path.basename(local_file_name)}\"]\n",
    "        verify_result = subprocess.run(verify_cmd, capture_output=True, text=True)\n",
    "        if verify_result.returncode != 0:\n",
    "            raise RuntimeError(f\"Failed to verify the file '{local_file_name}' in the container '{container_name}'.\")\n",
    "\n",
    "        return f\"Copied {local_file_name} into {container_name}:{container_home_path}/.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f349e",
   "metadata": {},
   "source": [
    "Now, let's define the FileAccessAgent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f231d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents/file_access_agent.py\n",
    "from examples.agentic_solutions.resources.object_oriented_agents.core_classes.base_agent import BaseAgent\n",
    "from examples.agentic_solutions.resources.object_oriented_agents.core_classes.tool_manager import ToolManager\n",
    "\n",
    "class FileAccessAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    Agent that can only use the 'safe_file_access' tool to read CSV files.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, developer_prompt: str, model_name: str = \"gpt-4o\"):\n",
    "        super().__init__(developer_prompt, model_name)\n",
    "        self.setup_tools()\n",
    "\n",
    "    def setup_tools(self) -> None:\n",
    "        self.tool_manager = ToolManager()\n",
    "        # Register the one tool this agent is allowed to use\n",
    "        self.tool_manager.register_tool(FileAccessTool())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c2880835874a0",
   "metadata": {},
   "source": [
    "Let's define the FileAccessAgent. We'll define the tool definition and the tool call handler within the class to keep the code organized and coupled. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e09531ec65a167",
   "metadata": {},
   "source": [
    "Let's test this agent. We'll use Apple 2009-2024.csv file in the resources/data directory. Credits: [Apple Financials 2009-2024](https://www.kaggle.com/datasets/jamiedcollins/hjsjdjdjdjd?resource=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c5230309eaed34b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletionMessageToolCall' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m file_ingestion_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou are a helpful data science assistant. The user will provide the name of a CSV file that contains relational data. The file is in the directory ./resources/data\u001b[39m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mDo not include any additional commentary or code not related to reading the file.\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m  \n\u001b[1;32m     12\u001b[0m file_ingestion_agent \u001b[38;5;241m=\u001b[39m FileAccessAgent(file_ingestion_prompt)\n\u001b[0;32m---> 14\u001b[0m file_ingestion_agent_output \u001b[38;5;241m=\u001b[39m \u001b[43mfile_ingestion_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRead the file Apple 2009-2024.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_ingestion_agent_output)\n",
      "File \u001b[0;32m~/Workspace-9/cookbooks/examples/agentic_solutions/resources/core_classes/base_agent.py:60\u001b[0m, in \u001b[0;36mBaseAgent.task\u001b[0;34m(self, user_task, tool_call_enabled, return_tool_response_as_is)\u001b[0m\n\u001b[1;32m     57\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mtool_calls\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tool_call_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtool_manager \u001b[38;5;129;01mand\u001b[39;00m tool_calls:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Delegate to the tool manager for the full sequence\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_tool_call_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tool_response_as_is\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 5. No tool call, just a normal assistant response\u001b[39;00m\n\u001b[1;32m     68\u001b[0m response_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/Workspace-9/cookbooks/examples/agentic_solutions/resources/core_classes/tool_manager.py:74\u001b[0m, in \u001b[0;36mToolManager.handle_tool_call_sequence\u001b[0;34m(self, response, return_tool_response_as_is, messages, model_name)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tool_response\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Otherwise, feed the tool's response back to the LLM for a final answer\u001b[39;00m\n\u001b[1;32m     71\u001b[0m function_call_result_message \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_response,\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mfirst_tool_call\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     75\u001b[0m }\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Build a new message list\u001b[39;00m\n\u001b[1;32m     78\u001b[0m complete_payload \u001b[38;5;241m=\u001b[39m messages\u001b[38;5;241m.\u001b[39mget_messages()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletionMessageToolCall' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "file_ingestion_prompt = \"\"\"\n",
    "You are a helpful data science assistant. The user will provide the name of a CSV file that contains relational data. The file is in the directory ./resources/data\n",
    "\n",
    "Instructions:\n",
    "1. When the user provides the CSV file name, use the 'safe_read_file' tool to read and display the first 6 lines of that file.\n",
    "2. If the specified file does not exist in the provided directory, return an appropriate error message (e.g., \"Error: The specified file does not exist in the provided directory\").\n",
    "3. The user may request data analysis based on the file’s contents, but you should NOT perform or write code for any data analysis. Your only task is to read and return the first 6 lines of the file.\n",
    "\n",
    "Do not include any additional commentary or code not related to reading the file.\n",
    "\"\"\"  \n",
    "\n",
    "file_ingestion_agent = FileAccessAgent(file_ingestion_prompt)\n",
    "\n",
    "file_ingestion_agent_output = file_ingestion_agent.task(\"Read the file Apple 2009-2024.csv\")\n",
    "\n",
    "print(file_ingestion_agent_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06cd2e5447b4ff9",
   "metadata": {},
   "source": [
    "Define the second agent that can generate and execute code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7643989ed641c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonExecAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    An agent that can only call 'execute_python_code' to run Python code in a container.\n",
    "    \"\"\"\n",
    "    def get_tool_definition(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Returns the single tool (function) this agent can call.\n",
    "        \"\"\"\n",
    "        return ({\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"execute_python_code\",\n",
    "                        \"description\": \"Executes Python code securely in a container\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"python_code\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The Python code to execute\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"python_code\"]\n",
    "                        }\n",
    "                    }\n",
    "                })\n",
    "    \n",
    "    def handle_tool_call(self, tool_arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Handles the call to 'execute_python_code'.\n",
    "        \"\"\"\n",
    "        python_code = tool_arguments[\"python_code\"]\n",
    "        return self.execute_python_code(python_code)\n",
    "\n",
    "    def execute_python_code(self, code: str) -> str:\n",
    "        \"\"\"\n",
    "        Run Python code in a container and return the output.\n",
    "        \"\"\"\n",
    "        print(\"[PythonExecAgent] Executing Python code in a container:\")\n",
    "        code = code.strip('\"\"\"')\n",
    "        print(code)\n",
    "        # Function that actually runs code in a container\n",
    "        output, errors = self.run_code_in_container(code)\n",
    "        \n",
    "        if errors:\n",
    "            return f\"[Error]\\n{errors}\"\n",
    "        \n",
    "        return output\n",
    "\n",
    "    # Helper function to run code in the container \n",
    "    @staticmethod\n",
    "    def run_code_in_container(code: str, container_name: str = \"sandbox\") -> Tuple[str, str]:\n",
    "        # The command we run inside the container uses `python -c` and reads code from stdin.\n",
    "        # `exec(sys.stdin.read())` executes all code passed via stdin.\n",
    "        cmd = [\n",
    "            \"docker\", \"exec\", \"-i\", \n",
    "            container_name, \n",
    "            \"python\", \"-c\", \"import sys; exec(sys.stdin.read())\"\n",
    "        ]\n",
    "        \n",
    "        # Run the command, providing the code via stdin\n",
    "        process = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        out, err = process.communicate(code)\n",
    "\n",
    "        return out, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis_prompt = \"\"\"  \n",
    "You are a helpful data science assistant. The user will provide:\n",
    "\t1.\tThe name of a CSV file containing relational data in a table.\n",
    "\t2.\tThe first 6 lines of the CSV (headers plus sample rows) to clarify column names and data types.\n",
    "\t3.\tA question or a task about the data.\n",
    "\n",
    "Your task is to generate a Python script that:\n",
    "\t1.\tAnswers the user’s question or task by analyzing the DataFrame.\n",
    "\t2.\tChecks if the specified file exists in the current directory before reading. If it does not exist, return an error message:\n",
    "\"Error: The specified file does not exist in the current directory\".\n",
    "\t3.\tHandles potential mismatches in column names or data types.\n",
    "\t4.\tUses only Python standard libraries plus pandas, numpy, matplotlib, and seaborn.\n",
    "\t5.\tGenerate only the Python code in a single code block (no explanatory text or comments). \n",
    "    6.  Call the tool execute_python_code that will execute the code inside a docker container. \n",
    "    7.  Because the code is executed inside a container there is no display attached to the output. \n",
    "    8.  Always return the output from the code execution. \n",
    "    9.  If the code generates an image or a plot, print the plot as base64 encoded image to stdout. sys.stdout.write(encoded_image). Don't use any extraneous text.\n",
    "\t10.\tPut appropriate error handling such as the column names and data types are not as expected.\n",
    "\n",
    "Files if specified in the prompt are in the directory /home/sandboxuser\n",
    "\"\"\"\n",
    "\n",
    "data_analysis_agent = PythonExecAgent(data_analysis_prompt)\n",
    "\n",
    "data_analysis_agent_output = data_analysis_agent.task(f\"\"\"What was Apple's revenue in 2024?\\n\n",
    "                                                      {file_ingestion_agent_output}\"\"\")\n",
    "\n",
    "print(data_analysis_agent_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb93488f",
   "metadata": {},
   "source": [
    "### Step 3: Set up Agentic Orchestration to run the application \n",
    "\n",
    "Let's get a data set with thousands of rows that couldn't possibly fit in the context window of the LLM, and see if our agentic orchestration can handle it with the help of the code interpreter. We will usee APPL.csv file in the resources/data directory. Credits: [Kaggle.com Apple Stock Data](https://www.kaggle.com/datasets/varpit94/apple-stock-data-updated-till-22jun2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import base64\n",
    "import binascii\n",
    "\n",
    "def is_base64(s):\n",
    "    try:\n",
    "        base64.b64decode(s, validate=True)\n",
    "        return True\n",
    "    except binascii.Error:\n",
    "        return False\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Please enter your question or task. Type 'exit' to stop.     \")\n",
    "    if user_input == \"exit\":\n",
    "        print(\"Exiting the application.\")\n",
    "        break\n",
    "    question = user_input\n",
    "\n",
    "    print(\"------------------- Question or task -------------------\")\n",
    "    print(question)\n",
    "\n",
    "    file_ingestion_agent_output = file_ingestion_agent.task(question)\n",
    "\n",
    "    print(\"------------------- Step 1 Understanding the contents of the file -------------------\")\n",
    "    print(file_ingestion_agent_output)\n",
    "\n",
    "    data_analysis_agent = PythonExecAgent(data_analysis_prompt)\n",
    "\n",
    "    print(\"------------------- Step 2 Generating the Python script and executing it in a container -------------------\")\n",
    "    data_analysis_agent_output = data_analysis_agent.task(f\"\"\"{question} + \"\\n\" + {file_ingestion_agent_output}\"\"\")\n",
    "\n",
    "    print(\"------------------- Step 3 Displaying the output -------------------\")\n",
    "    if is_base64(data_analysis_agent_output):\n",
    "        # decode image\n",
    "        decoded_image = base64.b64decode(data_analysis_agent_output)\n",
    "        display(Image(data=decoded_image))\n",
    "    else:\n",
    "        # handle text\n",
    "        print(data_analysis_agent_output)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
